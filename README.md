
# Sentiment Analysis with DistilBERT + PEFT (LoRA) ğŸš€

## Overview
This project demonstrates how to fineâ€‘tune **DistilBERT** for sentiment classification and then apply **Parameterâ€‘Efficient Fineâ€‘Tuning (PEFT)** with **LoRA adapters** to achieve strong performance while keeping training lightweight and scalable.

Beyond experimentation, the project shows how to **deploy the model in production** using:
- **FastAPI** for serving predictions via REST API
- **Docker** for containerization and reproducibility
- **AWS EC2** for hosting the service in the cloud

---

## âœ¨ Key Highlights
- Compared **base model fineâ€‘tuning** vs. **LoRA adapter training**
- Showcased how **PEFT reduces compute cost** while maintaining accuracy
- Built a reproducible workflow for sentiment analysis with Hugging Face + PEFT
- Wrapped the model in a **FastAPI app**, containerized with **Docker**, and deployed on **EC2**

---
## Quick Road Map of the Project

```mermaid
flowchart TD
    A[Load DistilBERT Base Model] --> B[Fineâ€‘Tune for Sentiment Classification]
    B --> C[Apply PEFT - LoRA Adapters]
    C --> D[Save Adapter + Config]
    D --> E[FastAPI Service for Inference]
    E --> F[Docker Containerization]
    F --> G[Deploy on AWS EC2 Instance]
    G --> H[Public API Endpoint]

---

## ğŸ› ï¸ Tech Stack
- **Model**: DistilBERT (Hugging Face Transformers)
- **Fineâ€‘Tuning**: PEFT (LoRA adapters)
- **Serving**: FastAPI + Uvicorn
- **Containerization**: Docker
- **Deployment**: AWS EC2

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ main.py              # FastAPI app entrypoint
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile           # Container build instructions
â”œâ”€â”€ notebooks/           # Training & fineâ€‘tuning experiments
â””â”€â”€ README.md            # Project documentation
```

---

## âš¡ Quickstart

### 1. Clone the repo
```bash
git clone https://github.com/yourusername/sentiment-api.git
cd sentiment-api
```

### 2. Build Docker image
```bash
sudo docker build -t sentiment-api .
```

### 3. Run container
```bash
sudo docker run -it --rm -p 10000:10000 sentiment-api
```

### 4. Test API
```bash
curl -X POST http://localhost:10000/predict \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this movie!"}'
```

---

## ğŸŒ Deployment on EC2
1. Launch an EC2 instance (Ubuntu recommended).
2. Install Docker:
   ```bash
   sudo apt update && sudo apt install docker.io -y
   ```
3. Pull your repo and build:
   ```bash
   git pull origin main
   sudo docker build -t sentiment-api .
   sudo docker run -it --rm -p 10000:10000 sentiment-api
   ```
4. Open port **10000** in your EC2 security group.
5. Access your API at:
   ```
   http://<your-ec2-public-ip>:10000/
   ```

---

## ğŸ”’ Optional: Nginx Reverse Proxy + HTTPS
For production, you can serve the API on port 80/443 with Nginx and secure it using Letâ€™s Encrypt.

---

## ğŸ“Š Example Response
```json
{
  "label": "POSITIVE",
  "score": 0.987
}
```

---

## ğŸ“š References
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [PEFT Library](https://huggingface.co/docs/peft)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Docker](https://docs.docker.com/)
- [AWS EC2](https://docs.aws.amazon.com/ec2/)

---

## ğŸš€ Future Work
- Add CI/CD pipeline for automated deployment
- Extend to multiâ€‘class sentiment datasets
- Benchmark inference latency under load

---

## ğŸ‘¨â€ğŸ’» Author
Built with â¤ï¸ by arjun1998

```

---




